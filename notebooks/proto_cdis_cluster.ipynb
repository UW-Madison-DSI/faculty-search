{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "Kyle: I had an idea that I wanted to run past you. As you know DSI will move to the new CDIS building in about a year. There is some discussion about arranging the faculty from computer science, statistics, and biomedical informatics into interdisciplinary “pods”. They are trying to come up with some themes that would achieve this goal. It’s basically a clustering problem. I was thinking that it might be cool to use the vector store to aid in this.\n",
    "Possible approaches:\n",
    "make a few TSNE / PCA plots restricted to papers by faculty in those departments [either on the web or exported as html with plotly]\n",
    "make a few TSNE / PCA plots by faculty instead of by paper (using the mean or a barrycenter of their papers) [either on the web or exported as html with plotly]\n",
    "try a few clustering approaches on either 1) papers or 2) faculty\n",
    "attempt to use GPT to suggest categories similar to the taxonomy project for news feed.\n",
    "\n",
    "\n",
    "Departments:\n",
    "1. Statistics\n",
    "1. CS\n",
    "1. BMI\n",
    "1. Information school\n",
    "\n",
    "Steps:\n",
    "1. Get all departments' faculty\n",
    "1. Get all papers from faculty\n",
    "1. Get all papers' embeddings\n",
    "1. Cluster all papers\n",
    "1. Define clusters and generate descriptions with a list people involved (not yet implemented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all departments' faculty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from embedding_search.academic_analytics import get_units, get_faculties, get_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = get_units()\n",
    "for unit in units:\n",
    "    print(f\"{unit['unit']['id']}: {unit['unit']['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_units = {\n",
    "    \"28603\": \"Department of Computer Sciences\",\n",
    "    \"28673\": \"Department of Statistics\",\n",
    "    \"28591\": \"Department of Biostatistics and Medical Informatics\",\n",
    "    \"28634\": \"Information School\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_list = []\n",
    "for unit_id, name in selected_units.items():\n",
    "    print(f\"{unit_id}: {name}\")\n",
    "    unit_faculties = get_faculties(unit_id)\n",
    "\n",
    "    sel_faculties = [f for f in unit_faculties if f[\"isNonFaculty\"] == False]\n",
    "    for f in sel_faculties:\n",
    "        f[\"unit\"] = name\n",
    "\n",
    "    faculty_list.extend(sel_faculties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-download all authors in selected departments/units (expansive, run once)\n",
    "\n",
    "# from crawl import download_all_authors_in_unit\n",
    "# for unit_id, name in selected_units.items():\n",
    "#     print(f\"Downloading unit in {name}\")\n",
    "#     download_all_authors_in_unit(unit=unit_id, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load downloaded data to memory\n",
    "authors = []\n",
    "for x in faculty_list:\n",
    "    try:\n",
    "        authors.append(get_author(x[\"id\"]))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Author {x['id']} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect all papers embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "embeddings = []\n",
    "article_titles = []\n",
    "article_doi = []\n",
    "\n",
    "# Collect useful information\n",
    "for a in authors:\n",
    "    embeddings.extend(a.articles_embeddings)\n",
    "    for article in a.articles:\n",
    "        article_titles.append(article.title)\n",
    "        article_doi.append(article.doi)\n",
    "        names.append(a.first_name + \" \" + a.last_name)\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of articles: {len(article_titles)}\")\n",
    "print(f\"Number of authors: {len(names)}\")\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "print(f\"Number of dois: {len(article_doi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster all papers (on full vector) and make 2d projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some basic 2d projections\n",
    "projection_pca = PCA(n_components=2).fit_transform(embeddings)\n",
    "projection_2d = TSNE(n_components=2, random_state=0).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack into dataframe\n",
    "df_tsne = pd.DataFrame(projection_2d, columns=[\"x_tsne\", \"y_tsne\"])\n",
    "df_pca = pd.DataFrame(projection_pca, columns=[\"x_pca\", \"y_pca\"])\n",
    "df = pd.concat([df_tsne, df_pca], axis=1)\n",
    "df[\"title\"] = article_titles\n",
    "df[\"doi\"] = article_doi\n",
    "df[\"name\"] = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply K-Mean clustering\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(embeddings)\n",
    "df[\"cluster\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how kMean match with 2d projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "pca_plot = (\n",
    "    alt.Chart(df)\n",
    "    .mark_circle()\n",
    "    .encode(x=\"x_pca\", y=\"y_pca\", color=\"cluster:N\", tooltip=[\"title\", \"doi\", \"name\"])\n",
    "    .interactive()\n",
    ")\n",
    "\n",
    "tsne_plot = pca_plot.encode(\n",
    "    x=\"x_tsne\",\n",
    "    y=\"y_tsne\",\n",
    ")\n",
    "\n",
    "pca_plot | tsne_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T-SNE seems match kMean better, export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot.properties(\n",
    "    title=\"k-mean clustering with tsne projection summarizing all published works\",\n",
    "    width=800,\n",
    "    height=800,\n",
    ").save(\"explore_cdis.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
